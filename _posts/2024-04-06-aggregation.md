---
layout: post
title: "Some thoughts on aggregation"
description: "Some ideas that summarize my submission essay for the Complexity Global School for Emerging Political Economies July 2024"
date: 2024-04-06 00:05:00
categories: commentary
thumbnail: assets/img/posts/2024/thumbnail_1.jpg
---

I recently finished my essay submission (you can read it [here](../../../../assets/pdf/submission_complexity_santafe.pdf) ) for a summer school on complexity that will be held in July 2024. It took me several days to finish the essay, mostly because I was overwhelmed on trying to settle down on a concrete idea regarding what I wanted to do in the program if I were to be accepted. As I was reading the transcription of a [talk](https://100r.co/site/computing_and_sustainability.html) at StrangeLoop 2023 (a conference held at St. Louis, Missouri) I stumbled with the following paragraph: 

>  The resilience of a garden, or a farm, is about interdependence. Companion planting is when two plants are grown near each other to benefit one of those plants, by fending off insects, for example.

> What is ideal is an ecosystem of many solutions. Looking for a single one is a distraction from all this discourse. 

This made me think how systems, in the more abstract sense, whether we're talking about a computer, society or a particular computer software, share a huge number of similarities. Perhaps abstract mathematical thinking has been significantly restrained from us because once I saw [Eugenia Cheng's talk](https://www.youtube.com/watch?v=48VqWQ2YbGk&t=1091s) in which she uses the same structure of a power set to gain insights into thinking about privilege. These similarities shared by systems, for example how resilience, equilibrium, and other concepts don't seem to pertain to any specific system are hints of a potential underlying structure, or perhaps just *one* potential underlying structure, so as to avoid assuming that phenomena have only one particular structure to be discovered by us humans. I just cannot wait until category theory is taught in schools, and I dream of a moment in which children won't be let down by not getting arithmetic or even calculus, there is just so much joy and fun in thiking abstractly, wether it by about matrices, functions, functionals, groups, or even categories. 

In my submission I discussed microfoundations, and just last month an [article by Dimand (2024)](https://doi.org/10.4000/oeconomia.16900) in OEconomia discussed the misunderstanding of James Tobin's disagreement of overlapping generations models (OLG). His disagreement "was the use of OLG modeling, combined with the assumption that no asset other than fiat money exists, to explain the existence and positive value of fiat money" (Dimand, 2024). I find interesting that already in 1960s he was aware of the discretion present in modelling, specifically in how the *adoption* of a certain model, like OLG, was in some applications inadequate. In his view, OLG was adequate for evaluating pension schemes but not to explain the positive value of fiat money. 

The aggregation problem that I wish to expore if I am accepted in the program, or I am rejected, stems from the concern that hierarchical systems like the market can be studied by moving the focus from the isolated individual towards the interaction of that elementary subsystem and the others. Initially I was just bothered by the fact that after such fuzz regarding behavioral economics giving insights as to why rationality wasn't as we expected, basic models are *still* taught in economics programs. I thought that after Simon's contribution of bounded rationality and the plethora of experiments that followed suit identifying biases and other nuances in rationality would've pushed us to reevaluate the basics. Not it is no longer that concerning because I guess one could say that there are many cases in which Kahneman's system 2 thinking kicks in and thus our models do give valuable insights (and predictions). But putting interactions back in the map, beyond just monotonic relationships (like how the network effect) but with a closer look. Yes, that seems like a hard task, but 

As a side and bonus rant towards economics is that in the beginnings we borrowed several concepts from physics (equilibrium, velocity, elasticity) and brought in the mathematical tools to study them (I have yet to find a reference to this, if after reading Walras' *Éléments* or Jevons' *Theory of Political Economy* I still don't find it I'll be worried), but ironically, we ignored the relevance of **negligible** forces, or at least we don't have the capacity to empirically observe negligibility of something, it seems much more like an imposition by the researcher. I know this because more often than not my professors would invoke a personal example or an **intuition** (entirely based off of their own personal experience...which is even more ironic) to argument why such and such ignored factor has a negligible effect on the entire phenomenon. All in the name of science and objectivity...or perhaps in the name of tractability ([Cherrier, 2023](https://journals.openedition.org/oeconomia/14116)), convenience ([Lucas, 1980, footnote 11](https://www.jstor.org/stable/1992030?origin=crossref)) and just lazy applied maths ([McCloskey, 2005](https://www.deirdremccloskey.com/articles/stats/stats.php)). 

